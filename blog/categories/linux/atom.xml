<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: linux | Like的世界]]></title>
  <link href="http://www.malike.net.cn/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://www.malike.net.cn/"/>
  <updated>2020-04-30T17:23:58+00:00</updated>
  <id>http://www.malike.net.cn/</id>
  <author>
    <name><![CDATA[Like Ma]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Snap简介]]></title>
    <link href="http://www.malike.net.cn/blog/2020/04/30/snap-tutorial/"/>
    <updated>2020-04-30T19:40:24+00:00</updated>
    <id>http://www.malike.net.cn/blog/2020/04/30/snap-tutorial</id>
    <content type="html"><![CDATA[<p><a href="https://snapcraft.io/">Snap</a> 是 Canonical 开发的包管理系统，默认安装于 Ubuntu 16.04 及其后的发行版本中。</p>

<p>优势：</p>

<ul>
<li>自包含：不受限于发行版的系统库版本，且每个包之间不存在运行库依赖。</li>
<li>只读挂载：应用程序不能修改或删除，且不会污染系统应用程序或库。</li>
<li>回退：内置回退旧版本。</li>
<li>快照：内置备份和恢复应用数据。</li>
<li>版本新：相比发行版更新缓慢，其应用程序版本都比较新。</li>
</ul>


<p>劣势主要为安装包占用较多存储空间。</p>

<h2>一、安装 snapd</h2>

<pre><code class="bash">sudo apt install -y snapd
</code></pre>

<p>查看版本</p>

<pre><code class="bash">snap version
</code></pre>

<h2>二、安装 snap 包</h2>

<pre><code class="bash">sudo snap install lxd
</code></pre>

<p>默认 <code>stable</code> 频道，也可以指定 <code>edge</code> 频道：</p>

<pre><code class="bash">sudo snap install --channel=edge lxd
</code></pre>

<p>安装后，可切换频道。</p>

<pre><code class="bash">sudo snap switch --channel=stable lxd
</code></pre>

<p>相比 RPM 和 Debian 包需手动更新，snap 包将在后台自动更新。若需手动更新，则</p>

<pre><code class="bash">sudo snap refresh lxd
</code></pre>

<p>snap 还能切换频道并更新</p>

<pre><code class="bash">sudo snap refresh --channel=beta lxd
</code></pre>

<p>snap 应用程序位于 <code>/snap/bin</code> ，如： <code>/snap/bin/lxd</code></p>

<p>为便于使用，可将该路径追加于 <code>~/.bashrc</code> 或 <code>~/.zshrc</code> 环境变量 <code>PATH</code> ，如：</p>

<pre><code class="bash">export PATH=$PATH:/snap/bin
</code></pre>

<h2>三、搜索包</h2>

<pre><code class="bash">snap search &lt;snapname&gt;
</code></pre>

<p>也可通过浏览器在应用市场 <a href="https://snapcraft.io/">Snapcraft</a> 上搜索需要的包（应用）。</p>

<h2>四、列表已安装的包</h2>

<h3>列表所有包</h3>

<pre><code class="bash">snap list
</code></pre>

<p>输出：</p>

<pre><code>Name      Version    Rev    Tracking       Publisher   Notes
core      16-2.44.3  9066   latest/stable  canonical✓  core
core18    20200311   1705   latest/stable  canonical✓  base
lxd       4.0.1      14804  latest/stable  canonical✓  -
</code></pre>

<p>若 <code>--all</code> ， 则列表包的所有版本 (revision)</p>

<h3>列表指定包</h3>

<pre><code class="bash">snap list lxd
</code></pre>

<p>输出：</p>

<pre><code>Name  Version  Rev    Tracking       Publisher   Notes
lxd   4.0.1    14804  latest/stable  canonical✓  -
</code></pre>

<h2>五、回退版本</h2>

<pre><code class="bash">sudo snap revert lxd
</code></pre>

<p>若遇到当前版本bug，则可考虑回退程序。当前跟踪的 channel 不会因上一版本源于不同 channel 而改变。</p>

<ul>
<li><code>snap refesh</code> 不会更新已回退的包，除非指定包名，如：<code>snap refresh lxd</code></li>
<li>新版本发布，将继续自动更新已回退的包。</li>
</ul>


<h2>六、卸载 snap 包</h2>

<pre><code class="bash">sudo snap remove lxd
</code></pre>

<p>卸载旧版本（释放空间）。</p>

<pre><code class="bash">sudo snap remove --revision=14709 lxd
</code></pre>

<h2>七、启用/禁用 snap 包</h2>

<p>为避免卸载和重装而禁用：</p>

<pre><code class="bash">sudo snap disable lxd
</code></pre>

<p>反之：</p>

<pre><code class="bash">sudo snap enable lxd
</code></pre>

<h2>八、服务</h2>

<h3>列表</h3>

<pre><code class="bash">sudo snap services lxd
</code></pre>

<p>输出：</p>

<pre><code>Service       Startup  Current   Notes
lxd.activate  enabled  inactive  -
lxd.daemon    enabled  active    socket-activated
</code></pre>

<h3>启动、停止和重启</h3>

<pre><code class="bash">sudo snap stop lxd.daemon
sudo snap start lxd.daemon
sudo snap restart lxd.daemon
</code></pre>

<p>停止服务，并禁用自动启动：</p>

<pre><code class="bash">sudo snap stop --disable lxd.daemon
</code></pre>

<p>开始服务，并启用自动启动：</p>

<pre><code class="bash">sudo snap start --disable lxd.daemon
</code></pre>

<h3>查看日志</h3>

<pre><code class="bash">sudo snap logs lxd
sudo snap logs lxd.daemon
sudo snap logs lxd -f # 类似tail -f
</code></pre>

<h2>九、快照</h2>

<h3>创建</h3>

<pre><code class="bash">sudo snap save
</code></pre>

<p>输出：</p>

<pre><code>Set  Snap      Age    Version    Rev    Size    Notes
1    core      42.2s  16-2.44.3  9066     124B  -
1    core18    42.2s  20200311   1705     123B  -
1    lxd       42.2s  4.0.1      14890   2187B  -
</code></pre>

<p>或指定包</p>

<pre><code class="bash">sudo snap save lxd
</code></pre>

<p>若 <code>--no-wait</code>， 则后台运行。</p>

<h3>列表</h3>

<pre><code class="bash">snap saved
</code></pre>

<p>或指定Set ID</p>

<pre><code class="bash">snap saved --id=1
</code></pre>

<h3>校验</h3>

<pre><code class="bash">snap check-snapshot 1
</code></pre>

<h3>还原</h3>

<pre><code class="bash">snap restore 1
</code></pre>

<h3>删除</h3>

<pre><code class="bash">snap forget 1
</code></pre>

<h2>十、剖析</h2>

<h3>包的安装</h3>

<p>相比 RPM 和 Debian 等传统安装包，通过解开来安装。</p>

<p>存于 <code>/var/lib/snapd</code> ，格式为 <a href="https://en.wikipedia.org/wiki/SquashFS">squashfs</a> 的 snap 包，不直接解开，而是（只读）挂载至 <code>/snap/&lt;snapname&gt;/&lt;revision&gt;</code> 目录。如：</p>

<p><code>lxd</code> 的 revision 14890 的包存储于 <code>/var/lib/snapd/snaps/lxd_14890.snap</code> :</p>

<pre><code class="bash">mount | grep 14890
</code></pre>

<p>发现：</p>

<pre><code>/var/lib/snapd/snaps/lxd_14890.snap on /snap/lxd/14890 type squashfs (ro,nodev,relatime)
</code></pre>

<p>另外， <code>/snap/&lt;snapname&gt;/current</code> 为当前版本挂载点，它为指向 <code>/snap/&lt;snapname&gt;/&lt;revision&gt;</code> 的符号链接。</p>

<p>而且，每个 snap 包含了不依赖系统库的完整的运行时库。</p>

<h3>包的缓存</h3>

<p>snap 为了加速二次安装，首次安装会将 snap 包缓存至 <code>/var/lib/snapd/cache</code> 。</p>

<p>目前为止， snap 未提供命令清楚缓存。若需 <strong>释放空间</strong> ，须手动删除该目录中的文件。</p>

<h3>包的运行数据</h3>

<p><code>/var/snap</code> 存储每个包的运行数据（或元数据）。如：<code>/var/snap/lxd</code> 主要为 lxd 的元数据。</p>

<p>该目录或将消耗大量的存储空间，因受制于 AppArmor ，不能通过移动目录（至另外分区）和符号链接来释放空间，须 <code>mount --bind</code> 移动的目录。</p>

<h3>包的应用程序</h3>

<p><code>/snap/bin</code> 存储指向包的应用程序（符号链接），如：</p>

<pre><code class="bash">ls -l /snap/bin/lxd
</code></pre>

<p>看到 <code>lxd</code> 仅为 <code>snap</code> 的符号链接</p>

<pre><code>lrwxrwxrwx 13 root 29 4月  12:10 /snap/bin/lxd -&gt; /usr/bin/snap
</code></pre>

<h3>快照</h3>

<p>每个包快照用独立的 zip 文件存储，包含：</p>

<ul>
<li><code>meta.json</code> : 描述快照内容、配置和校验码。</li>
<li><code>archive.tgz</code> : 包含系统数据。</li>
<li><code>user/&lt;username&gt;.tgz</code> : 包含每个系统的用户数据。</li>
</ul>


<p>快照存储于 <code>/var/lib/snapd/snapshots</code></p>

<h2>参考</h2>

<ul>
<li><a href="https://snapcraft.io/docs/getting-started">Snap Getting Started</a></li>
<li><a href="http://landofnightandday.blogspot.com/2018/06/disable-snap-core-service-on-ubuntu-1804.html">Disable snap core service on Ubuntu 18.04</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Shadowsocks-Rust简介]]></title>
    <link href="http://www.malike.net.cn/blog/2019/04/30/shadowsocks-rust-tutorial/"/>
    <updated>2019-04-30T01:30:00+00:00</updated>
    <id>http://www.malike.net.cn/blog/2019/04/30/shadowsocks-rust-tutorial</id>
    <content type="html"><![CDATA[<p>在《<a href="https://www.malike.net.cn/blog/2016/11/29/shadowsocks-tutorial/">Shadowsocks简介</a>》中，我介绍了如何使用<a href="https://shadowsocks.org/en/index.html">Shadowsocks</a>。但它不具备负载均衡集群能力，而结合HAProxy的集群配置复杂。</p>

<p><a href="https://github.com/shadowsocks/shadowsocks-rust">shadowsocks-rust</a>是Shadowsocks的Rust语言实现，它不仅具有传统Shadowsocks特性，而且还具有：</p>

<ul>
<li><strong>负载均衡</strong> 多个Shadowsocks服务器的能力。</li>
<li>探测Shadowsocks服务器 <strong>延迟</strong> 的能力。</li>
</ul>


<h2>安装</h2>

<p>Shadowsocks-Rust未提供DEB安装包。为了方便安装，可下载其<a href="https://github.com/shadowsocks/shadowsocks-rust/releases">静态链接版本</a></p>

<pre><code class="bash">sudo tar atf shadowsocks-v1.7.0-nightly.x86_64-unknown-linux-musl.tar.xz -C /usr/local/bin
</code></pre>

<h2>配置</h2>

<p>以root用户创建目录/etc/shadowsocks-rust，编辑/etc/shadowsocks-rust/config.json：</p>

<pre><code class="json">{
    "servers": [
        {
            "address": "127.0.0.1",
            "port": 1080,
            "password": "hello-world",
            "method": "aes-256-cfb"
            "timeout": 300
        },
        {
            "address": "127.0.0.1",
            "port": 1081,
            "password": "hello-kitty",
            "method": "aes-256-cfb"
        }
    ],
    "local_port": 8388,
    "local_address": "127.0.0.1"
}
</code></pre>

<ul>
<li><code>address</code>为服务端地址。</li>
<li><code>server_port</code>为服务端监听端口。</li>
<li><code>password</code>为客户端和服务端预设的共享密码，它最好由安全密码生成器生成（如<a href="https://www.lastpass.com/">LastPass</a>或<a href="http://keepass.info/">KeePass</a>），且长度不小于6个字符。</li>
<li><code>timeout</code>为连接超时时间。</li>
<li><code>method</code>为加密算法，<code>aes-256-cfb</code>的安全性较好。</li>
<li>每个<code>servers</code>元素为一个Shadowsocks服务器配置。</li>
</ul>


<p>因Ubuntu 14.04过保，下面仅以Ubuntu 16.04及以后版本为例。</p>

<p>以root用户创建/etc/systemd/system/shadowsocks-rust-local.service:</p>

<pre><code class="ini">[Unit]
Description=Shadowsocks-Rust Custom Client Service.
Documentation=sslocal -h
After=network.target

[Service]
Type=simple
CapabilityBoundingSet=CAP_NET_BIND_SERVICE
AmbientCapabilities=CAP_NET_BIND_SERVICE
User=nobody
Group=nogroup
ExecStart=/usr/local/bin/sslocal --log-without-time -c /etc/shadowsocks-rust/config.json

[Install]
WantedBy=multi-user.target
</code></pre>

<p>注册并启动服务：</p>

<pre><code class="bash">sudo chown -R root:nogroup /etc/shadowsocks-rust
sudo chmod -R g-w,o-rwx /etc/shadowsocks-rust
sudo systemctl daemon-reload
sudo systemctl enable shadowsocks-rust
sudo systemctl start shadowsocks-rust
</code></pre>

<p>注：</p>

<ul>
<li>为降低<code>sslocal</code>进程权限，以nobody用户和nogroup组运行它。</li>
<li>为防止密码泄漏，/etc/shadowsocks-rust/config.json仅root用户或nogroup组可读。</li>
<li>限制<code>sslocal</code>进程仅能监听socket.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Shadowsocks简介]]></title>
    <link href="http://www.malike.net.cn/blog/2016/11/29/shadowsocks-tutorial/"/>
    <updated>2016-11-29T01:39:55+00:00</updated>
    <id>http://www.malike.net.cn/blog/2016/11/29/shadowsocks-tutorial</id>
    <content type="html"><![CDATA[<p><a href="https://shadowsocks.org/en/index.html">Shadowsocks</a>（中文名: 影梭） 是一款开源的安全SOCKS 5代理，它主要用于在大陆翻墙。</p>

<h2>原理</h2>

<p>与SSH动态代理相似，客户端呈现为SOCKS 5代理服务，客户端与服务器之间采用加密通信。服务器部署于GFW之外，从而实现代理翻墙服务。</p>

<h2>特点</h2>

<ul>
<li>使用自行设计的协议加密通信，支持多种加密算法：AES、Blowfish、IDEA、RC4等。除创建TCP连接外无需握手，每次请求只转发1个连接，因此使用起来网速较快，在移动设备上较省电。</li>
<li>通过异步I/O和事件驱动实现，响应速度快。</li>
<li>客户端支持主流操作系统平台：Windows、Linux、OS X、Android、iOS和OpenWrt</li>
</ul>


<h2>shadowsocks-libev简介</h2>

<p>网络中普遍采用Python版本的<a href="https://pypi.python.org/pypi/shadowsocks">shadowsocks</a>，该版本看似安装简单，却存在如下缺点：</p>

<ul>
<li>没有Linux操作系统原生安装包（如：RPM和DEB）：从Ubuntu 16.04开始，提供shadowsocks安装包。</li>
<li>没有操作系统的服务脚本（如init.d和upstart）。</li>
<li>Python程序占用内存较多，运行效率不佳。</li>
</ul>


<p>而<a href="https://github.com/shadowsocks/shadowsocks-libev">shadowsocks-libev</a>是Shadowsocks在嵌入式和低端设备的轻量级实现：</p>

<ul>
<li>纯C实现，不仅占用内存极小，且运行效率更快。</li>
<li>在几乎所有Linux平台都存在原生安装包，且具有对应平台的服务启动脚本。</li>
</ul>


<p>下面基于Ubuntu 14.04/16.04介绍它的安装和配置。</p>

<h2>安装shadowsocks-libev</h2>

<p>客户端和服务端的安装方法相同：</p>

<pre><code class="bash">sudo add-apt-repository ppa:max-c-lv/shadowsocks-libev
sudo apt-get update
sudo apt-get install -y shadowsocks-libev
</code></pre>

<h2>配置shadowsocks-libev服务端</h2>

<p>编辑/etc/shadowsocks-libev/config.json：</p>

<pre><code class="json">{
    "server_port": 8388,
    "password": "&lt;共享密码&gt;",
    "timeout": 60,
    "method": "aes-256-cfb"
}
</code></pre>

<ul>
<li><code>server_port</code>为服务端监听端口</li>
<li><code>password</code>为客户端和服务端预设的共享密码，它最好由安全密码生成器生成（如<a href="https://www.lastpass.com/">LastPass</a>或<a href="http://keepass.info/">KeePass</a>），且长度不小于6个字符。</li>
<li><code>timeout</code>为连接超时时间。</li>
<li><code>method</code>为加密算法，<code>aes-256-cfb</code>的安全性较好。</li>
</ul>


<p>配置完成后，需重启：</p>

<pre><code class="bash">sudo service shadowsocks-libev restart
</code></pre>

<h2>配置shadowsocks-libev客户端</h2>

<p>创建/etc/shadowsocks-libev/client.json （文件名可修改）：</p>

<pre><code class="json">{
    "server": "&lt;服务端地址&gt;",
    "server_port": "&lt;服务端端口&gt;",
    "local_port": "22357",
    "password": "&lt;共享密码&gt;",
    "method": "aes-256-cfb"
}
</code></pre>

<h3>Ubuntu 14.04</h3>

<p>安装包没有提供系统服务脚本，故须自己创建Upstart脚本/etc/init/ss-local.conf （文件名可修改）：</p>

<pre><code># ss-local

description "shadowsocks client"

start on (net-device-up IFACE=eth0 or net-device-up IFACE=wlan0)
stop on (net-device-down IFACE=eth0 and net-device-down IFACE=wlan0)

respawn

setuid nobody
setgid nogroup

exec ss-local -c /etc/shadowsocks-libev/client.json
</code></pre>

<p>为了client.json的安全：</p>

<pre><code class="bash">sudo chown -R root:nogroup /etc/shadowsocks-libev
sudo chmod 0750 /etc/shadowsocks-libev
sudo chmod 0640 /etc/shadowsocks-libev/client.json
</code></pre>

<p>启动客户端</p>

<pre><code class="bash">sudo start ss-local
</code></pre>

<p>最后，通过修改/etc/default/shadowsocks-libev的<code>START=no</code>禁止在客户机启动服务端程序——它在客户机没有作用。</p>

<pre><code class="bash">sudo service shadowsocks-libev stop
</code></pre>

<h3>Ubuntu 16.04</h3>

<p>安装包提供了systemd的服务模板/lib/systemd/system/shadowsocks-libev-local@.service</p>

<p>默认<code>ss-local</code>以root用户运行，可修改上述模板为nobody用户和nogroup组，从而提高安全：</p>

<pre><code>[Service]
Type=simple
CapabilityBoundingSet=CAP_NET_BIND_SERVICE
AmbientCapabilities=CAP_NET_BIND_SERVICE
User=nobody
Group=nogroup
ExecStart=/usr/bin/ss-local -c /etc/shadowsocks-libev/%i.json.
</code></pre>

<p>注意，升级shadowsocks-libev，模板将回复原状，须再次修改。</p>

<pre><code class="bash">sudo systemctl daemon-reload
sudo systemctl enable shadowsocks-libev-local@client
sudo systemctl start shadowsocks-libev-local@client
</code></pre>

<p>注意，@client与client.json的基本名必须一致。</p>

<p>最后，禁用并停止服务端程序：</p>

<pre><code class="bash">sudo systemctl disable shadowsocks-libev
sudo systemctl stop shadowsocks-libev
</code></pre>

<h2>集群化</h2>

<p>类似SSH集群，多个shadowsocks也可以构建SOCKS 5集群，具体请参考《<a href="http://www.malike.net.cn/blog/2015/03/15/ssh-proxy-cluster/">SSH翻墙集群</a>》的“HAProxy的配置方法”。</p>

<p>实用中发现，<code>ss-local</code>不会因为shadowsocks服务器是否可达，而停止运行或拒绝HAProxy连接。</p>

<p>导致HAProxy无法探测shadowsocks服务器是否离线或不可访问，部分负载将失败或重试（浏览器），从而影响体验。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SSH翻墙集群]]></title>
    <link href="http://www.malike.net.cn/blog/2015/03/15/ssh-proxy-cluster/"/>
    <updated>2015-03-15T21:30:43+08:00</updated>
    <id>http://www.malike.net.cn/blog/2015/03/15/ssh-proxy-cluster</id>
    <content type="html"><![CDATA[<p>SSH动态代理是国内较为常见的翻墙方法。正如<a href="/blog/2014/10/27/ssh-tunnel-tutorial/">SSH隧道简介</a>所说，它存在不少有优点。</p>

<p>然而在实际使用中，它存在如下缺点：</p>

<ul>
<li>与PPTP等VPN协议相比，它的连接不稳定。前者应该具备协议级断线重传机制。</li>
<li>基于廉价VPS，导致它的连接不稳定。而且廉价VPS容易掉线，有时需要用户自己找在线客户修复，进一步延长了掉线时间。</li>
<li>由于上述缺点，不适合小型公司多人使用。</li>
</ul>


<p>在大概2年前，我摸索出SSH动态代理集群的办法。并将之部署于我所服务的公司，成功负载了20-30人日常翻墙学习与工作的需求。</p>

<h2>原理</h2>

<p>SSH动态代理，即为SOCK5代理，所以我们需要的是SOCK5集群。</p>

<p>若搜索<a href="https://www.google.com/search?hl=en&amp;q=socks+5+load+balance">socks 5 load balance</a>不难发现一些有用信息：</p>

<p><a href="http://serverfault.com/questions/517971/what-is-the-best-way-to-load-balance-multiple-sock5-proxys-on-seperate-vms-in-t">What is the best way to load balance multiple sock5 proxys on seperate VM&rsquo;s in the same datacenter?</a></p>

<p>我将分别介绍3种方法搭建SOCK5集群：</p>

<ol>
<li>利用第三方模块<a href="https://github.com/yaoweibin/nginx_tcp_proxy_module">nginx_tcp_proxy_module</a>。</li>
<li>Nginx 1.9开始支持<a href="http://nginx.com/resources/admin-guide/tcp-load-balancing/">TCP Load Balancing</a>。</li>
<li><a href="http://www.haproxy.org/">HAProxy</a></li>
</ol>


<p>关于SSH动态代理的配置方法，请参看<a href="/blog/2014/12/23/autossh-tutorial/">AutoSSH简介</a></p>

<h2>nginx_tcp_proxy_module的配置方法</h2>

<p>Ubuntu的Nginx并没有将nginx_tcp_proxy_module编译进去。为了简化安装，我基于Ubuntu的Nginx包，做了Nginx的<a href="https://launchpad.net/~likemartinma/+archive/ubuntu/net">PPA</a>:</p>

<ul>
<li>升级Nginx版本</li>
<li>加入nginx_tcp_proxy_module</li>
</ul>


<p>添加我的PPA</p>

<pre><code class="bash">sudo add-apt-repository ppa:likemartinma/net
sudo apt-get -y update
</code></pre>

<p>若未安装nginx，则</p>

<pre><code class="bash">sudo apt-get install -y nginx
</code></pre>

<p>若已安装nginx，则</p>

<pre><code class="bash">sudo apt-get -y upgrade
</code></pre>

<p>在/etc/nginx/nginx.conf中，增加如下内容：</p>

<pre><code class="nginx">tcp {
    access_log /var/log/nginx/tcp_access.log;

    upstream ssh_cluster {
        # simple round-robin
        server 127.0.0.1:12345;
        server 127.0.0.1:12346;
        server 127.0.0.1:12347;

        check interval=3000 rise=2 fall=5 timeout=1000;
    }

    server {
        listen 9999;
        proxy_pass ssh_cluster;
    }
}
</code></pre>

<p>为了查看集群的状态，在/etc/nginx/sites-enabled/default的中，增加如下内容：</p>

<pre><code class="nginx">server {
    ...

    location /status {
        tcp_check_status;
    }
}
</code></pre>

<p>重启Nginx:</p>

<pre><code>service nginx restart
</code></pre>

<p>如此，访问http://&lt;cluster IP&gt;/status将能查看集群的详细状态。</p>

<h2>Nginx 1.9的配置方法</h2>

<p>Ubuntu 15.10之前的官方Nginx版本都小于1.9，须通过ppa:nginx/development升级nginx。</p>

<p>添加ppa:nginx/development</p>

<pre><code class="bash">sudo add-apt-repository ppa:nginx/development
sudo apt-get -y update
</code></pre>

<p>若未安装nginx，则</p>

<pre><code class="bash">sudo apt-get install -y nginx
</code></pre>

<p>若已安装nginx，则</p>

<pre><code class="bash">sudo apt-get -y upgrade
</code></pre>

<p>在/etc/nginx/nginx.conf中，增加如下内容：</p>

<pre><code class="nginx">stream {
    upstream ssh_cluster {
        least_conn;
        server 127.0.0.1:12345;
        server 127.0.0.1:12346;
        server 127.0.0.1:12347;
    }

    server {
        listen 9999;
        proxy_pass ssh_cluster;
    }
}
</code></pre>

<p>重启Nginx:</p>

<pre><code>service nginx restart
</code></pre>

<h2>HAProxy的配置方法</h2>

<p>安装haproxy</p>

<pre><code>sudo apt-get install -y haproxy
</code></pre>

<p>在/etc/haproxy/haproxy.cfg中，增加如下内容：</p>

<pre><code>frontend socks5
    mode tcp
    bind *:9999
    default_backend ssh_cluster

backend ssh_cluster
    mode tcp
    balance roundrobin
    server vps1 127.0.0.1:12345 weight 1 check inter 30000
    server vps2 127.0.0.1:12346 weight 1 check inter 30000
    server vps3 127.0.0.1:12347 weight 1 check inter 30000
</code></pre>

<p>为了查看集群的状态，在/etc/haproxy/haproxy.cfg中，增加如下内容：</p>

<pre><code>listen stats :9090
    balance
    mode http
    stats enable
    stats auth admin:admin
</code></pre>

<p>默认安装，haproxy处于不活动状态，须要激活它。</p>

<p>在/etc/default/haproxy中，修改如下行：</p>

<pre><code>ENABLED=1
</code></pre>

<p>最后，启动haproxy:</p>

<pre><code>service haproxy start
</code></pre>

<p>如此，访问http://&lt;cluster IP&gt;:9090/haproxy?stats将能查看集群的详细状态。</p>

<h2>总结</h2>

<ul>
<li>nginx_tcp_proxy_module有简单的集群状态页面。</li>
<li>nginx 1.9没有集群状态查页面，仅能通过错误日志/var/log/ngnix/error.log来查看掉线的集群节点。</li>
<li>haproxy不仅有完善的集群状态页面，而且不需要任何PPA，应该是最佳选择。</li>
<li>上述3种方法都缺乏认证机制，只能部署于家庭或企业内网。当然也可以部署于个人电脑，事实上，我就是这样使用的。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AutoSSH简介]]></title>
    <link href="http://www.malike.net.cn/blog/2014/12/23/autossh-tutorial/"/>
    <updated>2014-12-23T00:00:00+00:00</updated>
    <id>http://www.malike.net.cn/blog/2014/12/23/autossh-tutorial</id>
    <content type="html"><![CDATA[<p><a href="http://www.harding.motd.ca/autossh/">autossh</a> (Automatically restart SSH sessions and tunnels)，它在运行的时候启动一个SSH进程，并监控该进程的健康状况；当SSH进程崩溃或停止通信时，它将重启动SSH进程。</p>

<h2>命令选项</h2>

<pre><code class="bash">autossh [-V] [-M port[:echo_port]] [-f] [SSH_OPTIONS]
</code></pre>

<ul>
<li><p><strong>-M port[:echo_port]</strong> 指定监控端口（和echo端口，默认为前者加1）。</p>

<ul>
<li>若希望使远程标准inetd的echo服务（默认端口为7），则指定echo_port，仅需服务监听地址为localhost。</li>
<li>若port设置为0，则将禁用监控功能。仅在ssh退出后重启它。</li>
</ul>
</li>
<li><p><strong>-f</strong> 使autossh在后台运行。</p></li>
</ul>


<p>另外，autossh还提供了一组环境变量来控制其行为, 这里仅介绍几个有代表性的，其可以man autossh</p>

<ul>
<li><strong>AUTOSSH_FIRST_POLL</strong> 指定首次论询测试时间。</li>
<li><strong>AUTOSSH_POLL</strong> 指定连接论询时间，默认600。若该值小于两次网络超时（默认15秒），则网络超将被调整为该值的1/2</li>
<li><strong>AUTOSSH_GATETIME</strong> 指定等待SSH连接成功建立的时间，默认30秒，超时表示首次运行失败，将退出autossh。若设为0，则禁用该功能，通常用于启动时运行autossh。</li>
<li><strong>AUTOSSH_MAXLIFETIME</strong> 指autossh最长运行时间，达到该时间，autossh将退出，并杀死SSH进程。</li>
<li><strong>AUTOSSH_MAXSTART</strong> 指定SSH最大启动次数。默认-1，表示无限制。</li>
</ul>


<h2>Ubuntu配置方法</h2>

<p>基于Ubuntu 12.04或14.04，以SSH动态代理（即SSH翻墙）为例。init script和Upstart都可以将autossh变成服务，然Upstart的<em>respawn</em>容错能力更强，它能在服务进程掉线，重新启动该服务。</p>

<pre><code># autossh

description "autossh daemon"

start on (net-device-up IFACE=eth0 or net-device-up IFACE=wlan0)
stop on (net-device-down IFACE=eth0 and net-device-down IFACE=wlan0)

respawn

setuid like
setgid like

exec /usr/bin/autossh -M64000 -q -N -D localhost:12348 sshproxy
</code></pre>

<ul>
<li><em>setuid</em>和<em>setgid</em>为了让autossh运行在指定的用户和用户组上。</li>
<li><em>start on</em>表示当eth0或wlan0激活时，启动autossh，<em>stop on</em>反之。其目的为避免系统启动或网络掉线时，频繁尝试启动autossh。</li>
</ul>


<h2>更好的办法</h2>

<p>最近OpenSSH都支持选项<strong>ServerAliveInterval</strong>和<strong>ServerAliveCountMax</strong>，实际为建立在SSH协议上的心跳测试。当测试失败后，SSH客户端进程将退出。通过Upstart的respawn功能重启SSH客户端进程，也能达到autossh目的。</p>

<p>仍以SSH动态代理为例：</p>

<pre><code># sshproxy

description "ssh proxy"

start on (net-device-up IFACE=eth0 or net-device-up IFACE=wlan0)
stop on (net-device-down IFACE=eth0 and net-device-down IFACE=wlan0)

respawn

setuid like
setgid like

exec /usr/bin/ssh \
    -oServerAliveInterval=300 \
    -oServerAliveCountMax=2 \
    -q -N -D localhost:12348 sshproxy
</code></pre>
]]></content>
  </entry>
  
</feed>
